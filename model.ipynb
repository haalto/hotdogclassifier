{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy import asarray\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths for images\n",
    "train_not_hot_dog = \"train\\\\not_hot_dog\"\n",
    "train_hot_dog = \"train\\\\hot_dog\"\n",
    "test_not_hot_dog = \"test\\\\not_hot_dog\"\n",
    "test_hot_dog = \"test\\\\hot_dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 32\n",
    "channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for dowloading and prepping images\n",
    "def load_img_data(directory):\n",
    "    \n",
    "    counter = 0\n",
    "    images = []\n",
    "    \n",
    "    filenames = os.listdir(directory)\n",
    "    \n",
    "    \n",
    "    for filename in filenames:\n",
    "        img = Image.open(directory + \"\\\\\" + filename)\n",
    "        img = img.convert('L')\n",
    "        img = img.resize((img_size, img_size), Image.ANTIALIAS)\n",
    "        img = img.filter(ImageFilter.SHARPEN)\n",
    "        img = img.filter(ImageFilter.GaussianBlur(radius=2))\n",
    "        #img.show()\n",
    "        img = (asarray(img))\n",
    "        img = img.astype(float)\n",
    "        img = img.reshape(img_size, img_size, channels)        \n",
    "        images.append(img)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 complete\n",
      "2 complete\n",
      "3 complete\n",
      "4 complete\n"
     ]
    }
   ],
   "source": [
    "#Dowload the images with the function declared above\n",
    "\n",
    "train_img_not_hot_dog = load_img_data(train_not_hot_dog)\n",
    "print(\"1 complete\")\n",
    "train_img_hot_dog = load_img_data(train_hot_dog)\n",
    "print(\"2 complete\")\n",
    "test_img_not_hot_dog = load_img_data(test_not_hot_dog)\n",
    "print(\"3 complete\")\n",
    "test_img_hot_dog = load_img_data(test_hot_dog)\n",
    "print(\"4 complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup labels for training and testing\n",
    "training_size = len(train_img_not_hot_dog) + len(train_img_hot_dog)\n",
    "test_size = len(test_img_not_hot_dog) + len(test_img_hot_dog)\n",
    "\n",
    "training_labels_not_hot_dog = np.full((len(train_img_not_hot_dog), 2), (0, 1))\n",
    "training_labels_hot_dog = np.full((len(train_img_hot_dog), 2), (1, 0))\n",
    "training_labels = np.concatenate([training_labels_not_hot_dog, training_labels_hot_dog])\n",
    "\n",
    "test_labels_not_hot_dog = np.full((len(test_img_not_hot_dog), 2), (0, 1))\n",
    "test_labels_hot_dog = np.full((len(test_img_hot_dog), 2), (1, 0))\n",
    "test_labels = np.concatenate([test_labels_not_hot_dog, test_labels_hot_dog])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup training images and test images\n",
    "training_images = np.concatenate([train_img_not_hot_dog, train_img_hot_dog])\n",
    "test_images = np.concatenate([test_img_not_hot_dog, test_img_hot_dog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Image matrix shape\n",
    "training_images[277].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augment data\n",
    "datagen = ImageDataGenerator(\n",
    "                            rescale=1.0/255.0,\n",
    "                            rotation_range=15,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            shear_range=0.01,\n",
    "                            zoom_range=[0.3, 1.25],\n",
    "                            horizontal_flip=True,\n",
    "                            brightness_range=[0.5, 1.5],\n",
    "                            )\n",
    "train_iterator = datagen.flow(\n",
    "                              training_images, \n",
    "                              training_labels, \n",
    "                              batch_size=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model function\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same', input_shape=(img_size, img_size, channels)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imagesf, valid_imagesf, test_labelsf, valid_labelsf = train_test_split(test_images, test_labels, test_size=0.4, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "498/498 [==============================] - 86s 173ms/step - loss: 0.7006 - acc: 0.5082 - val_loss: 1.9981 - val_acc: 0.5300\n",
      "Epoch 2/20\n",
      "498/498 [==============================] - 76s 154ms/step - loss: 0.6911 - acc: 0.5188 - val_loss: 3.6356 - val_acc: 0.5250\n",
      "Epoch 3/20\n",
      "498/498 [==============================] - 79s 158ms/step - loss: 0.6838 - acc: 0.5459 - val_loss: 2.8101 - val_acc: 0.5700\n",
      "Epoch 4/20\n",
      "498/498 [==============================] - 84s 168ms/step - loss: 0.6789 - acc: 0.5570 - val_loss: 2.8155 - val_acc: 0.4950\n",
      "Epoch 5/20\n",
      "498/498 [==============================] - 83s 167ms/step - loss: 0.6751 - acc: 0.5656 - val_loss: 3.0614 - val_acc: 0.5750\n",
      "Epoch 6/20\n",
      "498/498 [==============================] - 77s 154ms/step - loss: 0.6652 - acc: 0.5844 - val_loss: 4.3844 - val_acc: 0.5600\n",
      "Epoch 7/20\n",
      "498/498 [==============================] - 71s 143ms/step - loss: 0.6615 - acc: 0.5913 - val_loss: 4.6643 - val_acc: 0.5750\n",
      "Epoch 8/20\n",
      "498/498 [==============================] - 72s 145ms/step - loss: 0.6526 - acc: 0.6054 - val_loss: 4.0794 - val_acc: 0.6100\n",
      "Epoch 9/20\n",
      "498/498 [==============================] - 70s 140ms/step - loss: 0.6429 - acc: 0.6195 - val_loss: 4.5997 - val_acc: 0.6000\n",
      "Epoch 10/20\n",
      "498/498 [==============================] - 66s 133ms/step - loss: 0.6381 - acc: 0.6282 - val_loss: 4.4691 - val_acc: 0.6100\n",
      "Epoch 11/20\n",
      "498/498 [==============================] - 66s 133ms/step - loss: 0.6307 - acc: 0.6336 - val_loss: 4.9414 - val_acc: 0.6200\n",
      "Epoch 12/20\n",
      "498/498 [==============================] - 65s 131ms/step - loss: 0.6211 - acc: 0.6452 - val_loss: 5.7981 - val_acc: 0.5850\n",
      "Epoch 13/20\n",
      "498/498 [==============================] - 66s 132ms/step - loss: 0.6160 - acc: 0.6486 - val_loss: 5.8418 - val_acc: 0.6050\n",
      "Epoch 14/20\n",
      "498/498 [==============================] - 65s 131ms/step - loss: 0.6038 - acc: 0.6598 - val_loss: 5.5404 - val_acc: 0.6200\n",
      "Epoch 15/20\n",
      "498/498 [==============================] - 68s 136ms/step - loss: 0.6008 - acc: 0.6597 - val_loss: 5.1884 - val_acc: 0.6500\n",
      "Epoch 16/20\n",
      "498/498 [==============================] - 74s 148ms/step - loss: 0.5849 - acc: 0.6816 - val_loss: 5.0525 - val_acc: 0.6300\n",
      "Epoch 17/20\n",
      "498/498 [==============================] - 74s 149ms/step - loss: 0.5784 - acc: 0.6830 - val_loss: 6.2109 - val_acc: 0.5950\n",
      "Epoch 18/20\n",
      "498/498 [==============================] - 81s 163ms/step - loss: 0.5698 - acc: 0.6928 - val_loss: 5.3781 - val_acc: 0.6200\n",
      "Epoch 19/20\n",
      "498/498 [==============================] - 98s 196ms/step - loss: 0.5698 - acc: 0.6923 - val_loss: 5.0980 - val_acc: 0.6450\n",
      "Epoch 20/20\n",
      "498/498 [==============================] - 99s 199ms/step - loss: 0.5608 - acc: 0.6997 - val_loss: 4.7050 - val_acc: 0.6650\n"
     ]
    }
   ],
   "source": [
    "model = define_model()\n",
    "history = model.fit_generator(train_iterator, steps_per_epoch=(len(training_images // 500)), epochs=20, validation_data=(valid_imagesf, valid_labelsf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing parameters\n",
    "ti = test_images\n",
    "tl = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test model\n",
    "datagen_test = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_generator = datagen_test.flow(ti, batch_size=1, shuffle=False)\n",
    "test_generator.reset()\n",
    "results = model.predict_generator(test_generator, steps=len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_test_labels = convert_output_labels(tl)\n",
    "conv_pred_labels = convert_output_labels(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.648"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final test score\n",
    "evaluate(conv_test_labels, conv_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for evaluation\n",
    "def evaluate(predicted_labels, ground_labels):\n",
    "    \n",
    "    set_length = len(ground_labels)\n",
    "    correct_labels = 0\n",
    "    \n",
    "    for i in range(0, set_length):\n",
    "        if predicted_labels[i] == ground_labels[i]:\n",
    "            correct_labels += 1\n",
    "    return (correct_labels/set_length)\n",
    "\n",
    "def convert_output_labels(data):\n",
    "    \n",
    "    labels = np.zeros(shape=[len(data), 1])\n",
    "    \n",
    "    for i in range(0, len(data)):\n",
    "        labels[i]= np.argmax(data[i])\n",
    "    return labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
